\section{Conclusion and Future Work}

In this thesis, we proposed a hybrid deep learning architecture for the classification of textile fabrics using both macro (RGB) and Optical Coherence Tomography (OCT) images. The model combines a Convolutional Neural Network (CNN) stream for learning localized texture-based features with a Vision Transformer (ViT) stream capable of modeling long-range spatial dependencies. By integrating these complementary feature extraction mechanisms, the proposed architecture effectively captures both fine-grained surface patterns and global contextual relationships within fabric images.

The experiments were conducted on two datasets: a standard RGB fabric dataset and an OCT dataset that offers high-resolution cross-sectional imaging of fabric microstructures. Extensive evaluations demonstrated that the hybrid model outperformed several existing methods, including VGG16, InceptionV3, ResNet101, MobileNetV2, and ConvNextBase. It achieved up to 99.66\% accuracy on the OCT dataset and 98.09\% accuracy on macro images for Wool fabrics, along with strong precision, recall, and F1-scores across all classes. Compared to prior works such as those by Hong et al.~\cite{hong2024research}, Chitra G M et al.~\cite{chitra2023fabric}, and Siam et al.~\cite{siam2023textilenet}, our approach offers a favorable balance between accuracy and computational efficiency.

The combination of CNN and ViT proved especially effective in overcoming the limitations of each individual approach. CNNs, though excellent at learning texture and local features, often lack global context modeling~\cite{simonyan2015vgg}. ViTs, while powerful in capturing spatial relationships~\cite{dosovitskiy2020vit}, benefit significantly from being paired with convolutional representations for low-level feature extraction. Our work supports this synergy and demonstrates the practical feasibility of deploying such models in industrial and retail settings.

\subsection*{Future Work}

While the results of this study are promising, they also open several avenues for further exploration and improvement. The following research directions could significantly advance the current framework and contribute to the broader field of intelligent textile analysis:

\begin{itemize}
    \item \textbf{Expansion to More Fabric Types:} This study focused on three foundational fabric types—Cotton, Polyester, and Wool—which are commonly used in textile manufacturing. However, the textile industry employs a much broader range of materials, including natural fibers like silk, flax, and hemp, and synthetic fibers such as nylon, acrylic, and spandex. Furthermore, modern garments often involve blended compositions, which introduce additional classification complexity. Future research could benefit from including such materials to evaluate model scalability and robustness under more diverse real-world conditions~\cite{kampouris2016fine}.
    
    \item \textbf{Multimodal Input Integration:} While this work utilized macro and OCT imaging modalities, future studies could integrate complementary imaging techniques such as hyperspectral imaging, thermal imaging, scanning electron microscopy (SEM), or fiber-level microscopy. These modalities can offer spectral, structural, or thermal cues that are not visible in standard images, thereby enabling better discrimination of subtle inter-class variations—particularly useful in detecting fabric blends, recycled materials, or surface defects~\cite{sabuncu2022optical}.
    
    \item \textbf{Lightweight Deployment and Optimization:} Although the proposed hybrid model achieves competitive accuracy with relatively low GFLOPs, real-time deployment on resource-constrained environments like embedded systems, handheld devices, or mobile apps may require further compression. Techniques such as model pruning, quantization, weight sharing, or knowledge distillation could be explored to reduce the model’s memory footprint and inference time without significant loss in accuracy~\cite{touvron2021training}. Additionally, frameworks such as TensorRT or ONNX can be used for deployment on production-grade inference engines.

    \item \textbf{Explainability and Interpretability:} In critical industrial applications, understanding how the model arrives at a prediction is essential for trust and validation. Incorporating explainability tools such as SHAP (SHapley Additive Explanations) and Grad-CAM (Gradient-weighted Class Activation Mapping)~\cite{selvaraju2017grad} would provide transparency into the decision-making process by highlighting important regions in the input image. This can help identify misclassifications, debug model behavior, and support human-in-the-loop validation in quality assurance pipelines.

    \item \textbf{Real-Time Systems and Industrial Integration:} Future work could focus on developing complete real-time systems that integrate fabric classification into industrial automation platforms. For instance, smart sorting systems on textile production lines could use live camera feeds and deploy lightweight models for immediate grading, quality checks, or material segregation. Incorporating defect detection, edge wear, dye consistency, and tear identification into such systems would significantly enhance their commercial value.
\end{itemize}
