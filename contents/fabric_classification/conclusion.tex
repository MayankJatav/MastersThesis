\section{Conclusion and Future Work}
\raggedbottom

In this thesis, we proposed a hybrid deep learning architecture for the classification of textile fabrics, using RGB (macro) and Optical Coherence Tomography (OCT) images. The architecture had a Convolutional Neural Network (CNN) stream for learning localized texture-based features in combination with a Vision Transformer (ViT) stream that was able to model long-range spatial dependencies. By combining these complementary means of feature extraction, the model was able to capture both the finer squeezed surface constituents and broad global contextual relationships found within fabric images.

The literature search and experiments were conducted on two datasets, a standard RGB fabric dataset and a dataset of OCT images that offered high-resolution cross-section imaging of the fabric micro-constituents (microstructures). The evaluation showed considerable performance against many previous models, including VGG16, InceptionV3, ResNet101, MobileNetV2, and ConvNextBase. Our models attained peak performance of 99.66\% accuracy on the OCT dataset, 98.09\% accuracy on macro images for Wool fabrics, and demonstrated solid precision, recall and F1-scores across all the classes. When comparing our performance to others like Hong et al.  Hong et al.~\cite{hong2024research}, Chitra G M et al.~\cite{chitra2023fabric}, and Siam et al.~\cite{siam2023textilenet}, it is evident we achieved a reasonable equivalency for measuring accuracy and efficiency.

By combining CNN with ViT, we were able to effectively compensate for the limitations of each approach. CNNs are certainly good at learning about texture and local features, but they typically do not model global context~\cite{simonyan2015vgg}. Conversely, ViTs think spatially and hence are very good at modeling spatial relations~\cite{dosovitskiy2020vit}. However, when used alone, they would require convolutional representation to extract low-level features. Our work confirms that there is value in using two models, and demonstrates that it can be effectively implemented in the context of industrial and retail applications.

\subsection*{Future Work}

While the findings in this research show great potential, they also introduce a number of avenues for continued investigation and development. The following research avenues could substantially help to build the current framework and provide value to the larger idea of intelligent textiles: 

\begin{itemize}
    \item \textbf{Expansion to More Fabric Types:} This study focused on three 'fundamental' fabric types-Cotton, Polyester, and Wool-that are textile manufacturers standard preferences. The textile industry has an enormous variety of materials available to them i.e., natural fibers- silk, flax, hemp, and synthetic fibers- nylon, acrylic, and spandex. In addition, modern garments are very often blended compositions, which adds complexity to the classification process. Research incorporating these variables might provide useful data to test the models versatility and resilience to more genuine and diverse scenarios~\cite{kampouris2016fine}.
    
    \item \textbf{Multimodal Input Integration:} This work incorporated a macro and OCT imaging domain, but future research could overlay complementary imaging modes like hyperspectral, scanning electron microscopy (SEM), or fiber microscopy. Each of these modalities can show spectral or structural that otherwise missed in standard images. This would allow for better separation of subtle inter-classes distinctions which may help with fabric blends, recycled materials, or surface defects~\cite{sabuncu2022optical}.
    
    \item \textbf{Lightweight Deployment and Optimization:} While the proposed hybrid model achieves competitive accuracy while consuming relatively few GFLOPs, it is likely that more compression will be required for real-time deployment in resource-constrained environments such as embedded systems, handheld devices, or mobile apps. Model compression can explore techniques such as model pruning, quantization, weight sharing, or knowledge distillation to reduce the memory foot print of the model and reduce inference time, but with an insignificant change in accuracy~\cite{touvron2021training}. Furthermore, TensorRT or ONNX can be used to deploy on production-grade inference engines. 

    \item \textbf{Explainability and Interpretability:} It is important to understand how the model makes a prediction in crucial industrial applications so the prediction can be trusted and validated. With an explainability tool such as SHAP (SHapley Additive Explanations) and Grad-CAM (Gradient-weighted Class Activation Mapping)~\cite{selvaraju2017grad} there will be transparency into the modelâ€™s decision-making process, by producing a gradient-weighted heat map to show the important regions in the input image. This transparency can help to find misclassifications, debug model behavior, and drive a human-in-the-loop validation process in quality assurance pipelines.

    \item \textbf{Real-Time Systems and Industrial Integration:} Future work could focus on developing complete real-time systems for industrial automation platforms with embedded fabric classifiers. For example, smart sorting systems on textile production lines might use video feeds with live camera images and light-weighted models to return immediate results for grading, quality checks, and separation of the textile material. Including defect detection, edge wear identification, dye consistency determination, and tear identification in these systems would increase their commercial viability.
\end{itemize}
