\section{Conclusion and Future Work}

In this thesis, we proposed a hybrid deep learning architecture that integrates Convolutional Neural Networks (CNNs) and Vision Transformers (ViTs) for the classification of textile fabrics using both RGB (macro) and OCT (micro) images. This design enables the model to capture localized texture-based features through CNNs and long-range spatial relationships via ViTs, providing a more comprehensive fabric representation.

We evaluated the model on three datasets: Fabrics, OCTFabrics, and TextileNet. On the Fabrics dataset, our model achieved an accuracy of 97.33\%, outperforming several baseline models and demonstrating superior performance over lightweight models such as Siam et al.'s MobileNetV2~\cite{siam2023textilenet}. For the OCTFabrics dataset, it achieved near-perfect accuracy of 99.66\% along with perfect precision, recall, and F1-score—showcasing strong discriminative power on microstructure-based data. Although MobileNetV2~\cite{siam2023textilenet} slightly surpassed our model in accuracy (99.87\%), our approach maintained significantly fewer parameters (28.97M vs.\ 42.72M).

On the more challenging TextileNet dataset, our model achieved 74.36\% accuracy, surpassing several popular architectures such as VGG16~\cite{simonyan2015vgg} and ConvNextBase. While Ying Hing et al.~\cite{hong2024research} and Chitra G M et al.~\cite{chitra2023fabric} reported higher accuracies (88.65\% and 88.06\% respectively), our model demonstrated better parameter efficiency and balanced performance, affirming its strong generalization ability across diverse fabric types.

Overall, the fusion of CNN and ViT streams helped overcome individual limitations—CNNs excel at local feature extraction but lack global context modeling, while ViTs provide spatial awareness but benefit from CNN-based low-level representations~\cite{dosovitskiy2020vit}. This synergy resulted in a robust, accurate, and efficient architecture suitable for real-world textile classification tasks in both industrial and retail settings.

\subsection*{Future Work}

While the findings in this research show great potential, they also introduce a number of avenues for continued investigation and development. The following research avenues could substantially help to build the current framework and provide value to the larger idea of intelligent textiles: 

\begin{itemize}
    \item \textbf{Expansion to More Fabric Types:} This study focused on three 'fundamental' fabric types-Cotton, Polyester, and Wool-that are textile manufacturers standard preferences. The textile industry has an enormous variety of materials available to them i.e., natural fibers- silk, flax, hemp, and synthetic fibers- nylon, acrylic, and spandex. In addition, modern garments are very often blended compositions, which adds complexity to the classification process. Research incorporating these variables might provide useful data to test the models versatility and resilience to more genuine and diverse scenarios~\cite{kampouris2016fine}.
    
    \item \textbf{Multimodal Input Integration:} This work incorporated a macro and OCT imaging domain, but future research could overlay complementary imaging modes like hyperspectral, scanning electron microscopy (SEM), or fiber microscopy. Each of these modalities can show spectral or structural that otherwise missed in standard images. This would allow for better separation of subtle inter-classes distinctions which may help with fabric blends, recycled materials, or surface defects~\cite{sabuncu2022optical}.
    
    \item \textbf{Lightweight Deployment and Optimization:} While the proposed hybrid model achieves competitive accuracy while consuming relatively few GFLOPs, it is likely that more compression will be required for real-time deployment in resource-constrained environments such as embedded systems, handheld devices, or mobile apps. Model compression can explore techniques such as model pruning, quantization, weight sharing, or knowledge distillation to reduce the memory foot print of the model and reduce inference time, but with an insignificant change in accuracy~\cite{touvron2021training}. Furthermore, TensorRT or ONNX can be used to deploy on production-grade inference engines. 

    \item \textbf{Explainability and Interpretability:} It is important to understand how the model makes a prediction in crucial industrial applications so the prediction can be trusted and validated. With an explainability tool such as SHAP (SHapley Additive Explanations) and Grad-CAM (Gradient-weighted Class Activation Mapping)~\cite{selvaraju2017grad} there will be transparency into the model’s decision-making process, by producing a gradient-weighted heat map to show the important regions in the input image. This transparency can help to find misclassifications, debug model behavior, and drive a human-in-the-loop validation process in quality assurance pipelines.

    \item \textbf{Real-Time Systems and Industrial Integration:} Future work could focus on developing complete real-time systems for industrial automation platforms with embedded fabric classifiers. For example, smart sorting systems on textile production lines might use video feeds with live camera images and light-weighted models to return immediate results for grading, quality checks, and separation of the textile material. Including defect detection, edge wear identification, dye consistency determination, and tear identification in these systems would increase their commercial viability.
\end{itemize}
